{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vadim BENICHOU\n",
    "##### Jennifer VIAL\n",
    "\n",
    "\n",
    "# Part I\n",
    "\n",
    "1. We reiterated the steps of the wordcounts assignement.  \n",
    "\n",
    "2. We made the HDFS steps to implement the data in HDFS. \n",
    "\n",
    "3. We created two text files : join1_FileA.txt and join1_FileB.txt\n",
    "\n",
    "Here are our inputs in the join1_FileA:\n",
    "able,991\n",
    "about,11\n",
    "burger,15\n",
    "actor,22\n",
    "\n",
    "\n",
    "Here are our inputs in the join1_FileB:\n",
    "Jan-01 able,5\n",
    "Feb-02 about,3\n",
    "Mar-03 about,8\n",
    "Apr-04 able,13\n",
    "Feb-22 actor,3\n",
    "Feb-23 burger,5\n",
    "Mar-08 burger,2\n",
    "Dec-15 able,100\n",
    "\n",
    "Last but not least, we aim at using our map and reduce python functions on these two functions through the command cat join1_File*.txt | ./join1_mapper.py | sort | ./join1_reducer.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code for the join1_mapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line       = line.strip()   #strip out carriage return\n",
    "    key_value  = line.split(\",\")   #split line, into key and value, returns a list\n",
    "    key_in     = key_value[0].split(\" \")   #key is first item in list\n",
    "    value_in   = key_value[1]   #value is 2nd item \n",
    "\n",
    "    #print key_in\n",
    "    if len(key_in)>=2:           #if this entry has <date word> in key\n",
    "        date = key_in[0]      #now get date from key field\n",
    "        word = key_in[1]\n",
    "        value_out = date+\" \"+value_in     #concatenate date, blank, and value_in\n",
    "        print( '%s\\t%s' % (word, value_out) )  #print a string, tab, and string\n",
    "    else:   #key is only <word> so just pass it through\n",
    "        print( '%s\\t%s' % (key_in[0], value_in) )  #print a string tab and string\n",
    "\n",
    "#Note that Hadoop expects a tab to separate key value\n",
    "#but this program assumes the input file has a ',' separating key value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code for the join1_reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "\n",
    "prev_word          = \"  \"                #initialize previous word  to blank string\n",
    "months             = ['Jan','Feb','Mar','Apr','Jun','Jul','Aug','Sep','Nov','Dec']\n",
    "\n",
    "dates_to_output    = [] #an empty list to hold dates for a given word\n",
    "day_cnts_to_output = [] #an empty list of day counts for a given word\n",
    "# see https://docs.python.org/2/tutorial/datastructures.html for list details\n",
    "\n",
    "line_cnt           = 0  #count input lines\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line       = line.strip()       #strip out carriage return\n",
    "    key_value  = line.split('\\t')   #split line, into key and value, returns a list\n",
    "    line_cnt   = line_cnt+1     \n",
    "\n",
    "    #note: for simple debugging use print statements, ie:  \n",
    "    curr_word  = key_value[0]         #key is first item in list, indexed by 0\n",
    "    value_in   = key_value[1]         #value is 2nd item\n",
    "\n",
    "    #-----------------------------------------------------\n",
    "    # Check if its a new word and not the first line \n",
    "    #   (b/c for the first line the previous word is not applicable)\n",
    "    #   if so then print out list of dates and counts\n",
    "    #----------------------------------------------------\n",
    "    if curr_word != prev_word:\n",
    "\n",
    "        # -----------------------     \n",
    "\t#now write out the join result, but not for the first line input\n",
    "        # -----------------------\n",
    "        if line_cnt>1:\n",
    "\t    for i in range(len(dates_to_output)):  #loop thru dates, indexes start at 0\n",
    "\t         print('{0} {1} {2} {3}'.format(dates_to_output[i],prev_word,day_cnts_to_output[i],curr_word_total_cnt))\n",
    "            #now reset lists\n",
    "\t    dates_to_output   =[]\n",
    "            day_cnts_to_output=[]\n",
    "        prev_word         =curr_word  #set up previous word for the next set of input lines\n",
    "\n",
    "\t\n",
    "    # ---------------------------------------------------------------\n",
    "    #whether or not the join result was written out, \n",
    "    #   now process the curr word    \n",
    "  \t\n",
    "    #determine if its from file <word, total-count> or < word, date day-count>\n",
    "    # and build up list of dates, day counts, and the 1 total count\n",
    "    # ---------------------------------------------------------------\n",
    "    if (value_in[0:3] in months): \n",
    "\n",
    "        date_day =value_in.split() #split the value field into a date and day-cnt\n",
    "        \n",
    "        #add date to lists of the value fields we are building\n",
    "        dates_to_output.append(date_day[0])\n",
    "        day_cnts_to_output.append(date_day[1])\n",
    "    else:\n",
    "        curr_word_total_cnt = value_in  #if the value field was just the total count then its\n",
    "                                           #the first (and only) item in this list\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "#now write out the LAST join result\n",
    "# ---------------------------------------------------------------\n",
    "for i in range(len(dates_to_output)):  #loop thru dates, indexes start at 0\n",
    "         print('{0} {1} {2} {3}'.format(dates_to_output[i],prev_word,day_cnts_to_output[i],curr_word_total_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the result, we enter the following commands in our terminal:\n",
    "hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \\\n",
    "-input /user/cloudera/input \\\n",
    "-output /user/cloudera/join1_output \\\n",
    "-mapper /home/cloudera/join1_mapper.py \\\n",
    "-reducer /home/cloudera/join1_reducer.py\n",
    "\n",
    "Thus in our join1_output.txt we get the following results:\n",
    "\n",
    "Dec-15 able 100 991\t\n",
    "Apr-04 able 13 991\t\n",
    "Jan-01 able 5 991\t\n",
    "Mar-03 about 8 11\t\n",
    "Feb-02 about 3 11\t\n",
    "Feb-22 actor 3 22\t\n",
    "Feb-23 burger 5 15\t\n",
    "Mar-08 burger 2 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "\n",
    "Firstly, by using make_join2data.py, we generated some datasets\n",
    "through the following scripts:\n",
    "\n",
    "python make_join2data.py y 1000 13 > join2_gennumA.txt \n",
    "\n",
    "python make_join2data.py y 2000 17 > join2_gennumB.txt\n",
    "\n",
    "python make_join2data.py y 3000 19 > join2_gennumC.txt\n",
    "\n",
    "python make_join2data.py n 100 23 > join2_genchanA.txt\n",
    "\n",
    "python make_join2data.py n 200 19 > join2_genchanB.txt\n",
    "\n",
    "python make_join2data.py n 300 37 > join2_genchanC.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the make_join2data script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "chans   = ['ABC','DEF','CNO','NOX','YES','CAB','BAT','MAN','ZOO','XYZ','BOB']\n",
    "sh1 =['Hot','Almost','Hourly','PostModern','Baked','Dumb','Cold','Surreal','Loud']\n",
    "sh2 =['News','Show','Cooking','Sports','Games','Talking','Talking']\n",
    "vwr =range(17,1053)\n",
    "\n",
    "chvnm=sys.argv[1]  #get number argument, if its n, do numbers not channels,\n",
    "\n",
    "lch=len(chans)\n",
    "lsh1=len(sh1)\n",
    "lsh2=len(sh2)\n",
    "lvwr=len(vwr)\n",
    "ci=1\n",
    "s1=2\n",
    "s2=3\n",
    "vwi=4\n",
    "ri=int(sys.argv[3])\n",
    "for i in range(0,int(sys.argv[2])):  #arg 2 is the number of lines to output\n",
    "\n",
    "    if chvnm=='n':  #no numuber\n",
    "        print('{0}_{1},{2}'.format(sh1[s1],sh2[s2],chans[ci]))\n",
    "    else:\n",
    "        print('{0}_{1},{2}'.format(sh1[s1],sh2[s2],vwr[vwi])) \n",
    "    ci=(5*ci+ri) % lch   \n",
    "    s1=(4*s1+ri) % lsh1\n",
    "    s2=(3*s1+ri+i) % lsh2\n",
    "    vwi=(2*vwi+ri+i) % lvwr\n",
    " \n",
    "    if (vwi==4): vwi=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "\n",
    "We put this files in a HDFS directory:\n",
    "\n",
    "join2_genchanA.txt\n",
    "\n",
    "join2_genchanB.txt\n",
    "\n",
    "join2_genchanC.txt\n",
    "\n",
    "join2_gennumA.txt\n",
    "\n",
    "join2_gennumB.txt\n",
    "\n",
    "join2_gennumC.txt\n",
    "\n",
    "4. \n",
    "\n",
    "Here, we have first to create new map / reduce python files, and use them to get the total number of viewers for shows on ABC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of our mapper: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line       = line.strip()   #strip out carriage return\n",
    "    key_value  = line.split(\",\")   #split line, into key and value, returns a list\n",
    "    key_in     = key_value[0].split(\" \")   #key is first item in list\n",
    "    value_in   = key_value[1]   #value is 2nd item \n",
    "\n",
    "    #print key_in\n",
    "    if (value_in == \"ABC\") or (value_in.isdigit()):           #if this entry equal 'ABC' or is a digit\n",
    "        print( '%s\\t%s' % (key_in[0], value_in) )  #print a string, tab, and string\n",
    "   \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Creation of our reducer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "import sys\n",
    "\n",
    "prev_show = \" \"\n",
    "abc_found = False\n",
    "\n",
    "shows_output = []\n",
    "viewers_output = []\n",
    "\n",
    "line_cnt = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "\tline = line.strip()\n",
    "\tkey_value = line.split('\\t')\n",
    "\tline_cnt = line_cnt+1\n",
    "\n",
    "\tcurr_show = key_value[0]\n",
    "\tvalue_in = key_value[1]\n",
    "\n",
    "\tif curr_show != prev_show:\n",
    "\t\t\n",
    "\t\tif abc_found == True:\n",
    "\t\t\n",
    "\t\t\tshows_output.append(prev_show)\n",
    "\t\t\tviewers_output.append(views)\n",
    "\n",
    "\t\tviews = 0\t\n",
    "\t\tabc_found = False\n",
    "\t\tprev_show = curr_show\n",
    "\t\t\n",
    "\tif value_in.isdigit():\n",
    "\t\tviews += int(value_in)\n",
    "\n",
    "\telse: \n",
    "\t\tabc_found = True\n",
    "\n",
    "if abc_found == True:\n",
    "\t\t\n",
    "\tshows_output.append(prev_show)\n",
    "\tviewers_output.append(views)\n",
    "\n",
    "for i in range(len(shows_output)):\n",
    "\tprint('{0} {1}'.format(shows_output[i], viewers_output[i]))\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the command bellow: \n",
    "\n",
    "hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
    "\n",
    "-input /user/cloudera/input_join2/ \n",
    "\n",
    "-output /user/cloudera/total_viewer_counts_output \n",
    "\n",
    "-mapper /home/cloudera/join2_mapper.py \n",
    "\n",
    "-reducer /home/cloudera/join2_reducer.py --numReduceTasks 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost_News 34491\n",
    "\n",
    "Almost_Show 60103\n",
    "\n",
    "Cold_Sports 62106\n",
    "\n",
    "Dumb_Show 54926\n",
    "\n",
    "Surreal_Sports 47935\n",
    "\n",
    "Hourly_Show 18582\n",
    "\n",
    "Dumb_Talking 114895\t\n",
    "\n",
    "Hot_Games 65241\t\n",
    "\n",
    "Hot_Show 84371\t\n",
    "\n",
    "Almost_Games 43247\t\n",
    "\n",
    "Hourly_Cooking 56309\n",
    "\n",
    "Baked_News 57312\n",
    "\n",
    "Hourly_Talking 118462\n",
    "\n",
    "Baked_Games 61703\n",
    "\n",
    "Loud_Show 51921\n",
    "\n",
    "PostModern_Games 51654\t\n",
    "\n",
    "Loud_Games 48591\n",
    "\n",
    "Surreal_News 63421\t\n",
    "\n",
    "Surreal_Talking 169459\n",
    "\n",
    "PostModern_News 61071\n",
    "\n",
    "Cold_News 48434\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we aim at implementing the vector-vector multiplication. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the vec mul mapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "\tline       = line.strip()   \n",
    "\tkey_value  = line.split(\",\")   \n",
    "\tkey_in     = key_value[0].strip()   \n",
    "\tvalue_in   = key_value[1].strip()   \n",
    "\tprint( '%s\\t%s' % (key_in, value_in) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the vec mul reducer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "prev.key = \" \"                \n",
    "total.sum = 0\n",
    "line.c = 0  \n",
    "\n",
    "for line in sys.stdin:\n",
    "    line       = line.strip()       \n",
    "    key_value  = line.split('\\t')   \n",
    "    line.c   = line.c+1     \n",
    "\n",
    "   \n",
    "    curr_key  = key_value[0].strip()         \n",
    "    value_in   = key_value[1].strip()         \n",
    "\n",
    "    if line.c==1:\n",
    "        prev_key= curr_key\n",
    "        curr_total = float(value_in)\n",
    "        continue\n",
    "\n",
    "    if (curr_key != prev_key):\n",
    "        total_sum+=curr_total\n",
    "        \n",
    "        curr_total = 0\n",
    "        prev.key= curr_key\n",
    "\t\n",
    "    # process the value\n",
    "    if curr_total ==0:\n",
    "        curr_total = float(value_in)\n",
    "    else:\n",
    "        curr_total *= float(value_in)\n",
    "# ---------------------------------------------------------------\n",
    "#now write out the LAST join result\n",
    "# ---------------------------------------------------------------\n",
    "total_sum+=curr_total\n",
    "print('total_dot_product ',total_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to implement the matrix-vector mapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "# input_dir = sys.argv[1]\n",
    "input_dir = '.'\n",
    "vector = [float(v) for v in open(input_dir+'/vector_file').readlines()]\n",
    "\n",
    "for line in sys.stdin:\n",
    "\tline       = line.strip()   \n",
    "\tkey_value  = line.split(\",\")   \n",
    "\ti     = int(key_value[0].strip())   \n",
    "\tj   = int(key_value[1].strip())   \n",
    "\tvalue   = float(key_value[2].strip())\n",
    "\tprint( '%s\\t%s' % (i, value*vector[j]) )\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to implement the matrix-vector reducer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "prev.key = \" \"                \n",
    "total.sum = 0\n",
    "line.c = 0 \n",
    "\n",
    "for line in sys.stdin:\n",
    "    line       = line.strip()       \n",
    "    key_value  = line.split('\\t')   \n",
    "    line.c   = line.c+1     \n",
    "\n",
    "    \n",
    "    curr_key  = key_value[0].strip()         \n",
    "    value_in   = key_value[1].strip()        \n",
    "\n",
    "    if line.c==1:\n",
    "        prev_key= curr_key\n",
    "        curr_total = float(value_in)\n",
    "        continue\n",
    "\n",
    "    if (curr_key != prev_key):\n",
    "        total_sum+=curr_total\n",
    "        print( '%s\\t%s' % (prev_key, curr_total) )\n",
    "        \n",
    "        curr_total = 0\n",
    "        prev_key= curr_key\n",
    "\t\n",
    "    # process the value\n",
    "    curr_total += float(value_in)\n",
    "# ---------------------------------------------------------------\n",
    "#now write out the LAST join result\n",
    "# ---------------------------------------------------------------\n",
    "print( '%s\\t%s' % (curr_key, curr_total) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
